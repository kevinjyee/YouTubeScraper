{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "vid_id_labels = {} # not used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing  fulldata\\train6l.tfrecord\n",
      "############# 1204 VIDEOS IN RECORD ##############\n",
      "\n",
      "Analyzed 1204 videos from YT8M\n"
     ]
    }
   ],
   "source": [
    "# - iterate over tensorflow record, one example at a time\n",
    "num_bad_labels = 0\n",
    "num_videos_in_record = 0\n",
    "\n",
    "import glob\n",
    "filenames = glob.glob('fulldata/*.tfrecord')\n",
    "featureDict = {}\n",
    "for video_level_data in filenames:\n",
    "    print('processing ',video_level_data)\n",
    "    \n",
    "    num_videos_in_part = 0\n",
    "    for example in tf.python_io.tf_record_iterator(video_level_data):\n",
    "        num_videos_in_record += 1\n",
    "        num_videos_in_part += 1\n",
    "        # yield example\n",
    "        tf_example = tf.train.Example.FromString(example)\n",
    "\n",
    "        # get video id from example\n",
    "        vid_id = tf_example.features.feature['video_id'].bytes_list.value[0].decode(encoding='UTF-8')\n",
    "        \n",
    "        # get list of labels from example\n",
    "        label_idx_list = tf_example.features.feature[\"labels\"].int64_list.value\n",
    "\n",
    "        # instantiate list for KEY=vid_id\n",
    "        featureDict[vid_id] = label_idx_list\n",
    "   \n",
    "\n",
    "    print('############# {} VIDEOS IN RECORD ##############'.format(num_videos_in_part))                    \n",
    "print('\\nAnalyzed {} videos from YT8M'.format(num_videos_in_record))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4716 entries, 0 to 4715\n",
      "Data columns (total 9 columns):\n",
      "Index               4716 non-null int64\n",
      "TrainVideoCount     4716 non-null int64\n",
      "KnowledgeGraphId    4716 non-null object\n",
      "Name                4639 non-null object\n",
      "WikiUrl             4639 non-null object\n",
      "Vertical1           4716 non-null object\n",
      "Vertical2           730 non-null object\n",
      "Vertical3           39 non-null object\n",
      "WikiDescription     4639 non-null object\n",
      "dtypes: int64(2), object(7)\n",
      "memory usage: 331.7+ KB\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('vocabulary.csv', header=0)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
